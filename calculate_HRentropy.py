"""
Calculation of Bayesian estimators of HR markers

This script takes a collection of estimated HR trajectories (as generated by
the script generate_hr.py) as inputs, and calculates HR entropy as introduced
in Ref. [1].  The script is based on code companion to the paper Ref. [2],
which implements the CTW algorithm introduced in Ref. [3].

[1] Rosas, F. E., Mediano, P. A., Timmermann, C., Luppi, A. I., Candia-Rivera,
D., Abbasi-Asl, R., ... & Carhart-Harris, R. (2023). The entropic heart:
Tracking the psychedelic state via heart rate dynamics. bioRxiv, 2023-11.

[2] Begleiter, R., El-Yaniv, R., & Yona, G. (2004). On prediction using
variable order Markov models. Journal of Artificial Intelligence Research, 22,
385-421.

[3] Willems, F. M., Shtarkov, Y. M., & Tjalkens, T. J. (1995). The context-tree
weighting method: Basic properties. IEEE Transactions on Information Theory,
41(3), 653-664.

Fernando Rosas & Pedro Mediano, March 2023
"""

#######################################################
# Loading packages
#######################################################
import numpy as np
import pandas as pd

# Java-related commands
import jpype as jp
if not jp.isJVMStarted():
    jp.startJVM(jp.getDefaultJVMPath(), '-ea', '-Xmx8192m', '-Djava.class.path=vmm.jar:trove.jar')    
jstr = jp.JPackage('java.lang').String
assert(jp.isJVMStarted())
javify = lambda py_str, ab_dict: jstr(bytearray([ab_dict[s] for s in py_str]))


#######################################################
# Functions 
#######################################################
def ctw_entropy(X, Y=None, vmm_order=30):
    '''
    Function for calculating HR entropy

    Parameters
    ----------
    X: pandas.DataFrame of float
        Dataframe containing the data over which the entropy will be
        calculated. Each of the columns is assumed to be a sample from the
        Bayesian posterior, as generated by the script generate_hr.py. 

    Y: pandas.DataFrame of float
        Dataframe containing the data used to train the probability
        distribution, which is evaluated on X for the estimation of the
        entropy. If none is given, the same data is used for training and
        evaluation.

    vmm_order: int
        Temporal horizon (measured in samples) of the probability model
        constructed by the CTW algorithm.

    Returns
    -------
    res: pandas.Series
        The estimated HR entropy for each sampled HR trajectory (i.e. one
        entropy value per column of X).

    '''
    # Set training data Y and build alphabet dictionary (used extensively later)
    if Y == None: # If none Y is given, use X as training data
        Y = X

    Yq = quantize_df(Y) # binarisation of training data
    alphabet = set(Yq.iloc[:,0]) # specification of which symbols the training data has
    ab_size = len(alphabet) # count how many different symbols are (usually 2)
    ab_dict = {cc: i for cc,i in zip(sorted(alphabet), range(ab_size))}

    # Initialise and train the probabilistic model
    vmm = jp.JPackage('vmm.algs').DCTWPredictor()
    vmm.init(ab_size, vmm_order)
    for e in Yq.columns: # each column is added as a different trial of equivalent data
        vmm.learn(javify(Yq[e], ab_dict)) 

    # Evaluate the model on the testing data X
    res = pd.Series(index=X.columns, dtype=float) # where the results will be stored
    Xq = quantize_df(X) # quantification of testing data
    for c in Xq.columns:
        data = Xq[c].values
        if len(data)==0:
            res.loc[c] = np.nan
        else:
            res.loc[c] = vmm.logEval(javify( data, ab_dict)) / len(data)

    return res


def quantize_df(data):
    '''
    Function to binarise data according to its mean value.

    Parameter
    ---------
    data : pandas.DataFrame of float

    Returns
    -------
    R : pandas.DataFrame of int with the same shape as the data, with 1 if the
    original value is above the column-wise mean value and 0 otherwise.
    '''
    data = data - data.mean()
    R = (data > 0).astype(int)
    return R


####################################
# Example of HR entropy estimation
####################################
if __name__ == '__main__':

    # Load Bayesian estimations
    data = pd.read_csv('bayes_hr.csv', index_col=0)

    # Calculate HR entropy
    data_diff = data.diff().dropna()
    h = ctw_entropy(data_diff)
    mean_h = h.mean()
    print('Average HR entropy: ', h.mean())

